{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87c3b211-be52-4c2f-aa25-fe882139fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4cf17db-ef7b-4806-a330-22cb5533382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MLP\n",
    "class MultiLayerPerceptron(nn.Sequential):\n",
    "    def __init__(self, input_dim, intern_dim, output_dim, depth = 2, isBiased = False):\n",
    "\n",
    "        self.depth = depth\n",
    "        if depth ==-1:\n",
    "            super(MultiLayerPerceptron, self).__init__()\n",
    "            self.layer = nn.Linear(input_dim, output_dim, bias=isBiased)\n",
    "        else:\n",
    "            dict = OrderedDict([(\"input\",nn.Linear(input_dim,intern_dim, bias=isBiased))])\n",
    "            for i in range(depth):\n",
    "                dict.update({str(i) : nn.Linear(intern_dim,intern_dim,bias=isBiased)})\n",
    "            dict.update({\"output\" : nn.Linear(intern_dim,output_dim,bias=isBiased)})\n",
    "            super().__init__(dict)\n",
    "\n",
    "        self.reset_init_weights_biases() # so that we do not use a default initialization\n",
    "\n",
    "    def reset_init_weights_biases(self, norm = None):\n",
    "        for layer in self.children():\n",
    "            if norm == None:\n",
    "                stdv = 1. / math.sqrt(layer.weight.size(1))\n",
    "            else :\n",
    "                stdv = norm\n",
    "            \n",
    "            layer.weight.data.uniform_(-stdv, stdv)\n",
    "            if layer.bias is not None:\n",
    "                layer.bias.data.uniform_(-stdv, stdv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6264e4dd-b9a9-4771-a27c-cecc585a9b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, input_data, output_data, untilConv = -1, lossFct = nn.MSELoss(), optimizer = 'SGD', lr=0.001, epochs = 20, batch_size=None, return_vals = True, init_norm = None, save = True, debug = False, savename='model.pt'):\n",
    "\n",
    "    if optimizer == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    elif optimizer == 'ASGD':\n",
    "        optimizer = torch.optim.ASGD(model.parameters(), lr=lr)\n",
    "    elif optimizer == 'GD':\n",
    "        optimizer = GD(model.parameters(), lr=lr)\n",
    "    \n",
    "    if init_norm is not None:\n",
    "        model.reset_init_weights_biases(init_norm)\n",
    "    \n",
    "    if return_vals:\n",
    "        errors = np.zeros(epochs)\n",
    "\n",
    "    n = len(input_data)\n",
    "    if batch_size is not None:\n",
    "        n_batches = n//batch_size\n",
    "\n",
    "    post_grad = 0\n",
    "    for i in range(epochs):\n",
    "        rand_idx = torch.randperm(n) # permutation of data samples\n",
    "        if batch_size is not None:\n",
    "            loss = 0\n",
    "            for t in range(n_batches):\n",
    "                idx = rand_idx[t*batch_size:(t+1)*batch_size]\n",
    "                y_pred = model(input_data[idx,:]).squeeze_()\n",
    "                loss += lossFct(y_pred, output_data[idx])\n",
    "        else:\n",
    "            y_pred = model(input_data[rand_idx,:]).squeeze_()\n",
    "            loss = lossFct(y_pred, output_data[rand_idx])\n",
    "            \n",
    "        if return_vals:\n",
    "            errors[i] = loss.item()\n",
    "\n",
    "            #if math.isnan(loss.item()):\n",
    "                #print(f\"Epoch: {i+1}   Loss: {loss.item()}\")\n",
    "                #break\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        grad = 0\n",
    "        for layer in model.children():\n",
    "            grad += layer.weight.grad.mean()\n",
    "        grad = abs(grad)\n",
    "        \n",
    "        if abs(post_grad - grad) <=untilConv:\n",
    "            print(\"Convergence\")\n",
    "            break\n",
    "        post_grad = grad\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        if debug:\n",
    "            if (i+1)%(epochs/debug) == 0:\n",
    "                print(f\"Epoch: {i+1}   Loss: {loss.item():.3e}\")\n",
    "\n",
    "    if save:\n",
    "        torch.save(model.state_dict(), DIRPATH+savename)\n",
    "    \n",
    "    if return_vals:\n",
    "        return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f9df884-154c-4465-81de-d3c96e4eb310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_data(p = 100, n = 500, sigma2 = 2):\n",
    "        ### Data generation\n",
    "    data = np.random.multivariate_normal(\n",
    "        np.zeros(p),\n",
    "        np.ones((p,p)),\n",
    "        size=n) # shape (n,p)\n",
    "\n",
    "    w_true = np.ones(p)*1/np.sqrt(p)\n",
    "\n",
    "    observations = [np.random.normal(\n",
    "        np.dot(w_true, x),\n",
    "        sigma2)\n",
    "        for x in data]\n",
    "    observations = np.array(observations) # shape (n,)\n",
    "\n",
    "    return data, observations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "024640f0-eca7-4019-906d-e0a8e919a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ridge_Lambda_Compute(A,b,LambdaArray):\n",
    "    error = np.zeros((LambdaArray.shape[0]))\n",
    "    for i in range(LambdaArray.shape[0]):\n",
    "        res = ridge(A,b,LambdaArray[i])\n",
    "        error[i] = objective(A,b,res)\n",
    "    ridgeErrorArray = np.hstack((LambdaArray[:,np.newaxis],error[:,np.newaxis]))\n",
    "    return ridgeErrorArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7234f33-fc96-4ff1-a2b2-bb915805ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weight(MLP):\n",
    "    sol_MLP = torch.eye(d)\n",
    "    for layer in MLP.children():\n",
    "        sol_MLP = sol_MLP@torch.transpose(layer.weight,0,1)\n",
    "    return sol_MLP.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cb24d38-0012-415c-8ad5-0cd6ded3fca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'input_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m A,b \u001b[38;5;241m=\u001b[39m Generate_data(p\u001b[38;5;241m=\u001b[39mp, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(depthArray\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m---> 19\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mMultiLayerPerceptron\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mintern_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintern_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepthArray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43misBiased\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     error,e \u001b[38;5;241m=\u001b[39m train(model, torch\u001b[38;5;241m.\u001b[39mfrom_numpy(A)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32), torch\u001b[38;5;241m.\u001b[39mfrom_numpy(b)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32), untilConv \u001b[38;5;241m=\u001b[39m untilConv, save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, epochs \u001b[38;5;241m=\u001b[39m epochs)\n\u001b[0;32m     25\u001b[0m     modelErrorArray[f,i] \u001b[38;5;241m=\u001b[39m error\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\Implicit_Regularization_SGD\\utils.py:122\u001b[0m, in \u001b[0;36mMultiLayerPerceptron.__init__\u001b[1;34m(self, input_dim, intern_dim, output_dim, depth, isBiased)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m depth \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28msuper\u001b[39m(MultiLayerPerceptron, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[43minput_size\u001b[49m, output_size, bias\u001b[38;5;241m=\u001b[39misBiased)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m,nn\u001b[38;5;241m.\u001b[39mLinear(input_dim,intern_dim, bias\u001b[38;5;241m=\u001b[39misBiased))])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_size' is not defined"
     ]
    }
   ],
   "source": [
    "%run utils.py\n",
    "%run Plot_lib.ipynb\n",
    "\n",
    "nb_avg=200\n",
    "p=100\n",
    "intern_dim= 10\n",
    "epochs = 2000\n",
    "untilConv = -1\n",
    "\n",
    "depthArray = np.array([-1,0,1,4,8,10])\n",
    "errorArray = np.zeros((nb_avg,depthArray.shape[0],2))\n",
    "modelErrorArray = np.zeros((nb_avg,depthArray.shape[0],epochs))\n",
    "\n",
    "for f in tqdm(range(nb_avg)):\n",
    "    \n",
    "    A,b = Generate_data(p=p, n=500)\n",
    "    \n",
    "    for i in range(depthArray.shape[0]):\n",
    "        model = MultiLayerPerceptron(input_dim=p,\n",
    "                                     intern_dim=intern_dim,\n",
    "                                     output_dim=1,\n",
    "                                     depth=depthArray[i],\n",
    "                                     isBiased = False)\n",
    "        error,e = train(model, torch.from_numpy(A).to(torch.float32), torch.from_numpy(b).to(torch.float32), untilConv = untilConv, save = False, epochs = epochs)\n",
    "        modelErrorArray[f,i] = error\n",
    "        errorArray[f,i] = [i,error[e]]\n",
    "    \n",
    "LambdaArray = np.logspace(0,2,100)\n",
    "ridgeErrorArray = Ridge_Lambda_Compute(A,b,LambdaArray)\n",
    "\n",
    "mean_errorArray = np.mean(errorArray, axis=0)\n",
    "print(mean_errorArray)\n",
    "mean_modelErrorArray = np.mean(modelErrorArray, axis=0)\n",
    "print(mean_modelErrorArray)\n",
    "\n",
    "plot_MvsR_overLambda(mean_errorArray, ridgeErrorArray)\n",
    "plot_M_overStep(mean_modelErrorArray,depthArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63da403-5efa-4f07-a8e4-f5353514c6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
